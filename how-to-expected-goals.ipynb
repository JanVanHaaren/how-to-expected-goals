{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tech how-to: Build your own expected-goals model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This how-to guides you through the process of building your own expected-goals model using popular data science and machine learning tools like Pandas, XGBoost, and scikit-learn. In this how-to, we discuss the following steps:\n",
    "1. Loading the data\n",
    "2. Preparing the data\n",
    "3. Constructing examples and datasets\n",
    "4. Learning a model\n",
    "5. Evaluating the model\n",
    "\n",
    "As part of this how-to, we release an artificial but realistic shots dataset containing information on 127,643 shots. To represent the shots, we adopt the SPADL representation, which we introduce in more detail in the following paper:\n",
    "\n",
    "**Actions Speak Louder Than Goals: Valuing Player Actions in Soccer**  \n",
    "Tom Decroos, Lotte Bransen, Jan Van Haaren, and Jesse Davis  \n",
    "[Read the full paper on arXiv](https://arxiv.org/abs/1802.07127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install missing packages\n",
    "!pip install pandas pyarrow xgboost sklearn scikit-plot scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import standard modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Import XGBoost classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Import scikit-learn functions\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import scikit-plot functions\n",
    "from scikitplot.metrics import plot_roc_curve\n",
    "from scikitplot.metrics import plot_precision_recall_curve\n",
    "from scikitplot.metrics import plot_calibration_curve\n",
    "\n",
    "# Import SciPy function\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-01-25 11:14:04--  https://github.com/JanVanHaaren/how-to-expected-goals/raw/master/shots.parquet\n",
      "Resolving github.com (github.com)... 140.82.118.3, 140.82.118.4\n",
      "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/JanVanHaaren/how-to-expected-goals/master/shots.parquet [following]\n",
      "--2019-01-25 11:14:05--  https://raw.githubusercontent.com/JanVanHaaren/how-to-expected-goals/master/shots.parquet\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.192.133, 151.101.128.133, 151.101.64.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.192.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7793234 (7,4M) [application/octet-stream]\n",
      "Saving to: ‘shots.parquet’\n",
      "\n",
      "shots.parquet       100%[===================>]   7,43M  14,7MB/s    in 0,5s    \n",
      "\n",
      "2019-01-25 11:14:06 (14,7 MB/s) - ‘shots.parquet’ saved [7793234/7793234]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://github.com/JanVanHaaren/how-to-expected-goals/raw/master/shots.parquet\" -O \"shots.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this how-to, we constructed an artificial but realistic shots dataset containing information on 127,643 shots. For each shot, the dataset contains the following information for the shot as well as the two actions immediately preceding the shot:\n",
    "* `game_id`: a unique identifier of the game;\n",
    "* `team_id`: a unique identifier of the team who performed the action;\n",
    "* `player_id`: a unique identifier of the player who performed the action;\n",
    "* `period`: 1 for the first half and 2 for the second half;\n",
    "* `seconds`: the time elapsed in seconds since the start of the half;\n",
    "* `type_id`: the identifier for the type of action;\n",
    "* `type_name`: the name for the type of action;\n",
    "* `body_part_id`: 0 for foot, 1 for head, 2 for other body part;\n",
    "* `result`: the result of the action: 0 for failure, 1 for success;\n",
    "* `start_x`: the x coordinate for the location where the action started, ranges from 0 to 105;\n",
    "* `start_y`: the y coordinate for the location where the action started, ranges from 0 to 68;\n",
    "* `end_x`: the x coordinate for the location where the action ended, ranges from 0 to 105;\n",
    "* `end_y`: the y coordinate for the location where the action ended, ranges from 0 to 68.\n",
    "\n",
    "The prefix `action` refers to the shot, whereas the prefixes `action1` and `action2` refer to the last and one-but-last action prior to the shot.\n",
    "\n",
    "The mapping between the `type_id` and `type_name` values is as follows:\n",
    "* 0: pass\n",
    "* 1: cross\n",
    "* 2: throw in\n",
    "* 3: freekick crossed\n",
    "* 4: freekick short\n",
    "* 5: corner crossed\n",
    "* 6: corner short\n",
    "* 7: take on\n",
    "* 8: foul\n",
    "* 9: tackle\n",
    "* 10: interception\n",
    "* 11: shot\n",
    "* 12: shot penalty\n",
    "* 13: shot freekick\n",
    "* 14: keeper save\n",
    "* 18: clearance\n",
    "* 21: dribble\n",
    "* 22: goalkick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.read_parquet('shots.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset contains 127643 shots.\n"
     ]
    }
   ],
   "source": [
    "number_of_shots = len(df_dataset)\n",
    "\n",
    "print('Our dataset contains {} shots.'.format(number_of_shots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           action_game_id\n",
       "1           action_team_id\n",
       "2         action_player_id\n",
       "3            action_period\n",
       "4           action_seconds\n",
       "5           action_type_id\n",
       "6         action_type_name\n",
       "7      action_body_part_id\n",
       "8            action_result\n",
       "9           action_start_x\n",
       "10          action_start_y\n",
       "11            action_end_x\n",
       "12            action_end_y\n",
       "13         action1_game_id\n",
       "14         action1_team_id\n",
       "15       action1_player_id\n",
       "16          action1_period\n",
       "17         action1_seconds\n",
       "18         action1_type_id\n",
       "19       action1_type_name\n",
       "20    action1_body_part_id\n",
       "21          action1_result\n",
       "22         action1_start_x\n",
       "23         action1_start_y\n",
       "24           action1_end_x\n",
       "25           action1_end_y\n",
       "26         action2_game_id\n",
       "27         action2_team_id\n",
       "28       action2_player_id\n",
       "29          action2_period\n",
       "30         action2_seconds\n",
       "31         action2_type_id\n",
       "32       action2_type_name\n",
       "33    action2_body_part_id\n",
       "34          action2_result\n",
       "35         action2_start_x\n",
       "36         action2_start_y\n",
       "37           action2_end_x\n",
       "38           action2_end_y\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df_dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the location features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to help the learning algorithm, we rescale the location features from their original scales to a normalized scale ranging from 0 to 1. More specifically, we divide the x coordinates by 105 and the y coordinates by 68."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for action in ['action', 'action1', 'action2']:\n",
    "    for side in ['start', 'end']:\n",
    "        \n",
    "        # Normalize the X location\n",
    "        key_x = '{}_{}_x'.format(action, side)\n",
    "        df_dataset[key_x] = df_dataset[key_x] / 105\n",
    "               \n",
    "        # Normalize the Y location\n",
    "        key_y = '{}_{}_y'.format(action, side)\n",
    "        df_dataset[key_y] = df_dataset[key_y] / 68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to predict the outcome of each shot, we need to transform our shots database into a dataset that we can fed into our machine learning algorithm. To this end, we perform the following three steps:\n",
    "\n",
    "1. We compute the Eucledian distances between the start locations of each of the three actions and the center of the opposing goal. We add these three distances as features to our dataset as we expect them to help our machine learning algorithm to learn a more accurate model.\n",
    "\n",
    "2. We construct our dataset by selecting a subset of the available features.\n",
    "\n",
    "3. We split the dataset into a train set for training the model and a hold-out test set for evaluating the model. This is an important step as we aim to learn a predictive model that generalizes well to unseen examples. By evaluating our model on a hold-out test set, we can investigate whether we are overfitting on the train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute additional features\n",
    "We compute the Eucledian distances between the start location of each of the three actions and the center of the opposing goal, which is located at coordinates (1, 0.5) in our normalized coordinate representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized location for the center of the opposing goal\n",
    "goal = (1, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distance to goal for each action's start location\n",
    "for action in ['action', 'action1', 'action2']:\n",
    "    key_start_x = '{action}_start_x'.format(action=action)\n",
    "    key_start_y = '{action}_start_y'.format(action=action)\n",
    "    key_start_distance = '{action}_start_distance'.format(action=action)\n",
    "\n",
    "    df_dataset[key_start_distance] = df_dataset.apply(lambda s: distance.euclidean((s[key_start_x], s[key_start_y]), goal), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine body part used for each action\n",
    "for action in ['action', 'action1', 'action2']:\n",
    "    key_body_part_id = '{action}_body_part_id'.format(action=action)\n",
    "    \n",
    "    key_is_foot = '{action}_is_foot'.format(action=action)\n",
    "    key_is_head = '{action}_is_head'.format(action=action)\n",
    "    key_is_other = '{action}_is_other'.format(action=action)\n",
    "\n",
    "    df_dataset[key_is_foot] = df_dataset[key_body_part_id] == 0\n",
    "    df_dataset[key_is_head] = df_dataset[key_body_part_id] == 1\n",
    "    df_dataset[key_is_other] = df_dataset[key_body_part_id] == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset.head(3).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the dataset\n",
    "We construct our dataset by selecting a subset of the available features. In this how-to, we use a limited number of features such as the location of the shot (`action_start_x` and `action_start_y`), the body part used by the shot taker (`action_body_part_id`), and the distances between the locations of the three actions and the center of the opposing goal (`action_start_distance`, `action1_start_distance`, and `action2_start_distance`).\n",
    "\n",
    "We encourage you to try other features as well and to investigate what effect they have on the performance of your expected-goals model. For example, you could try to include the angle between the shot location and the center of the goal or the angle between the shot location and the goal posts as a feature too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "columns_features = [\n",
    "    'action_start_x',\n",
    "    'action_start_y',\n",
    "    'action_is_foot',\n",
    "    'action_is_head',\n",
    "    'action_start_distance',\n",
    "    'action1_start_distance',\n",
    "    'action2_start_distance'\n",
    "]\n",
    "\n",
    "# Label: 1 if a goal, 0 otherwise\n",
    "column_target = 'action_result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_dataset[columns_features]\n",
    "y = df_dataset[column_target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into a train set and a test set\n",
    "We train our expected-goals model on 90% of the data and evaluate the model on the remaining 10% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn the model\n",
    "We learn our expected-goals model using the XGBoost algorithm, which is a popular algorithm in machine learning competitions like Kaggle. The algorithm is particularly appealing as it requires minimal parameter tuning to provide decent performance on many standard machine learning tasks.\n",
    "\n",
    "[Visit the XGBoost website for more information](http://xgboost.readthedocs.io/en/latest/model.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train an XGBoost classifier on our train set. We train 500 trees and set their maximum depth to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(objective='binary:logistic', max_depth=4, n_estimators=100)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "We evaluate the accuracy of our expected-goals model by making predictions for the shots in our test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each shot, predict the probability of the shot resulting in a goal\n",
    "y_pred = classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute area under the curve: receiver operating characteristic (AUC-ROC)\n",
    "To measure the accuracy of our expected-goals model, we compute the AUC-ROC obtained on the test set. The values for the AUC-ROC metric range from 0 to 1. The higher the AUC-ROC value is, the better the classifier is, where an AUC-ROC value of 0.50 corresponds to random guessing. That is, if we randomly predicted whether a shot results in a goal or not, we would obtain an AUC-ROC of 0.50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total = y_train.count()\n",
    "y_positive = y_train.sum()\n",
    "\n",
    "print('The training set contains {} examples of which {} are positives.'.format(y_total, y_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc = roc_auc_score(y_test, y_pred[:, 1])\n",
    "\n",
    "print('Our classifier obtains an AUC-ROC of {}.'.format(auc_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute area under the curve: precision-recall (AUC-PR)\n",
    "Since the AUC-ROC metric is susceptible to class imbalance (i.e., the number of positive examples is much lower or higher than the number of negative examples), we also compute the AUC-PR obtained on the test set. The values for the AUC-PR metric range from 0 to 1 too. The higher the AUC-PR value is, the better the classifier is. Unlike AUC-ROC, however, the value for random guessing does not necessarily correspond to 0.50 for imbalanced classes, but corresponds to the ratio of positive examples in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_pr_baseline = y_positive / y_total\n",
    "\n",
    "print('The baseline performance for AUC-PR is {}.'.format(auc_pr_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auc_pr = average_precision_score(y_test, y_pred[:, 1])\n",
    "\n",
    "print('Our classifier obtains an AUC-PR of {}.'.format(auc_pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot AUC-ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test, y_pred, curves='each_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot AUC-PR curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(y_test, y_pred, curves='each_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot calibration curve\n",
    "We plot a calibration curve to investigate how well our expected-goals model is calibrated. The plot shows the mean predicted value on the horizontal axis and the fraction of covered positive examples on the vertical axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(y_test, [y_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Perform grid search to find optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'max_depth': [4, 5, 6, 7, 8],\n",
    "    'n_estimators': [100, 250, 500, 1000, 1500, 2000]\n",
    "}\n",
    "\n",
    "classifier = XGBClassifier()\n",
    "classifier = GridSearchCV(classifier, parameters, scoring='roc_auc', verbose=2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:how-to-expected-goals]",
   "language": "python",
   "name": "conda-env-how-to-expected-goals-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
